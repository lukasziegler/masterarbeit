\section{Introduction}
\label{sec:introduction}

	% 1 Introduction
	Throughout the last decade public displays have evolved from screens used for advertisement, to interactive displays with bidirectional capability, enabling an entirely new type of interactive experience. With the rise of touch and gesture input, a new era of interactive applications is waiting to be used. Public displays can already be used at airports for finding your gate, in shopping malls as a store locator, or in brand stores for assessing user satisfaction and giving users a more immersive shopping experience. The areas of application for public displays are ever growing. However, still no common design guidelines exist \cite{Alt2012HowToEvaluate} and an individual evaluation of each setup is of importance \cite{muller2010requirements}. This reinforces the need for evaluating all new applications through lab or field studies. However, the evaluation of public displays however is a very time-consuming task and requires prior knowledge. 


	% Motivation, why we need a survey platform
	Based on the evaluation of related work and the time-consuming nature of field studies (even for small quantitative questionnaires) the demand for simplification and automation of the evaluation process becomes apparent. Due to the essential importance of the validation of public display installations and research in general, such an evaluation platform can be a great benefit. 
	% 2 Present Solutions / parallels to the Internet
	With the advent of the Internet a similar transition was visible. 
	%The ability of immediate responses enabled new ways of to conduct surveys.
	New capabilities such as direct feedback enabled new ways of to conduct surveys. Already in 1983 Sproull and Kiesler \cite{sproull1986reducing} looked at the benefits of email vs. traditional mail surveys. The demand for extensive evaluation of the new economy was met with emerging online survey platforms. One such survey platform is SurveyMonkey, founded in 1999 and currently one of the most popular solutions on the market to conduct web-based surveys \cite{SurveyMonkeyAboutUs}. Other well established solutions are eSurvey Creator, SoGoSurvey, and UX Suite by UsabilityTools. A closer evaluation can be found in chapter \ref{chapter:related-work}. These survey platforms focus on evaluating the users' opinion through web-based or mobile interfaces. 


	% 3 show their problems
	However, for our type of use the approaches which already exist aren't enough, since the evaluation of public displays requires additional requirements.
	One such constraint of public display research represents the opportunistic nature of the setups and the discrepancy between lab studies and field studies \cite{Ojala2011}. Thus there is an additional demand for evaluating each public display setup individually and if possible directly in the field. Another significant difference for evaluating public display setups is the additional abstraction layer. Not only is it of interest to understand how the user perceives the application, or to assess the users opinion independently of the display setup, but in particular what influence the context of the public display setup has on the users perception. Another important difference is that not only does the application itself needs to be evaluated, but so does the whole display setup including the influence of the surrounding environment. So far none of the platforms reviewed offers this level of evaluation.


	% 4 give REASONS, why to DEVELOP an new platform (requirements + benefits)
	To facilitate this step and to allow for a better comparison and analysis of public display setups, we developed \textit{PDSurvey}, an interactive public display survey platform. The interactive capability of public displays is of similar importance for our setup as the rising of the web in the late 1990s for online survey platforms. It is now possible to conduct surveys and to log data directly from public displays and to use the display itself as a feedback channel to the display provider.
	This facilitates the collection of quantitative and qualitative data from entire public display networks. When additionally collecting the context of every survey response, new insights into the differences between different display setups and the influence of the surrounding environment can be gathered. One interesting question could be which role the context plays on the users' perception of the public display setup, while running identical software settings, but only varying the context.

	% 5 Our contribution + research question
	Our research contributions are the categorization of questionnaires used for the evaluation of public displays, based on an extensive literature review. Furthermore we introduce the \textit{PDSurvey} platform, and present first practical experiences from our field study. We assess which feedback channel is preferred for responding to surveys. Our fundamental goal is to facilitate the evaluation of public display setups via interactive surveys on the displays themselves. Additionally we present results from the field study, including the motivation for approaching the display setup.

	% 6 Overview
	The main part of this thesis is structured as follows. Chapter \ref{chapter:related-work} provides an overview of related work and introduces the reader to the area of public display evaluation. In chapter \ref{chapter:literature-evaluation} we present the results of the literature evaluation and our clustering of standardized questionnaires. Chapter \ref{chapter:implementation} deals with the implementation of the \textit{PDSurvey} platform. First the requirements and design decisions are discussed, followed by a short overview of the architecture, and concluded with an overview of the finished platform. In chapter \ref{chapter:field-study} we present the descriptive field study and make first evaluations of our survey platform. Future work is discussed in chapter \ref{chapter:future-work}. A conclusion complements this thesis.







%% WIP NOTES FROM WRITING

	% Trend towards touch
	% With the introduction of the iPhone in 2007 and the iPad in 2010 users became much more accustomed to using screens with touch support. The increasing acceptance of touch screens combined with more sophisticated touch screen technology opens the path for interactive questionnaires in public settings. 



	% Public displays differ from other interactive displays by being owned by a display provider, and not by the user who is using it. 

	% Examples in research for new interactive applications are CityWall \cite{peltonen2008s}, MirrorTouch \cite{muller2014mirrortouch}, Digifieds \cite{}, Looking Glass \cite{}, ...

	% Already twenty years ago Mark Weiser described a new, third wave of computing, referred to as calm computing \cite{Weiser1995UbiqComp}.
