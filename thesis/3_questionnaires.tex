\section{Background}
\label{sec:questionnaires}
% 1 Standardized Questionnaires
% 2 Background


As a result of the literature review, besides getting a better understanding of how public displays were evaluated, a side effect was getting an overview of the questions asked to evaluate public displays and their applications. This turned out to be a quite valuable approach, since we haven't seen any compilation of questionnaires used for public display evaluation so far. Our goal was to find patterns and to build clusters of questionnaires being useful for the evaluation through automated public survey display platforms.

% Overview of this chapter
In the following we will first describe our methodology for gathering the information (section \ref{sec:questionnaires-methodology}), followed by a categorization of standardized questionnaires (section \ref{sec:questionnaires-categorization}), and wrapped up by a summary of our findings (section \ref{sec:questionnaires-findings}). The categorization of the standardized questionnaires can be found in Table \ref{table:standardized-questionnaires}.





\subsection{Methodology}
\label{sec:questionnaires-methodology}
% My Process: Approach for Collecting Information

	The procedure for the selection of papers to review, was as follows. As a starting point all papers form the appendix of Florian Alt's doctoral thesis \cite{alt2013thesis} were read. Afterwards interesting related work and citations were followed based on the papers from the previous step. This was supplemented with targeted research on Google Scholar and the APM Digital Library. To round off the literature review the publications of two authors, who are very active in this field, were reviewed. A full list of all papers reviewed can be found in Appendix \ref{appendix:papers}.

	% 1) Appendix
	The first step, the analysis of the appendix was fairly straight forward. All papers were read from start to finish (pages 335 to 343), in order to get a first overview of the current state of research. 
	% 2) Related Work / Citations
	The second step, pursuing related work and citations of interest, was carried out in a more subjective manner. Whenever interesting papers or projects were mentioned, the cited paper was also skimmed through. 
	% 3) Google Scholar Search + ACM
	For the third step, a more strategic approach was used. Based on the insights gained from the previous steps, Google Scholar and APM was checked for literature relevant to our research question. The Keywords, that were used amongst others for the research in these online libraries, were:
	\begin{itemize}[itemsep=0pt] 
	\item Standardized Surveys for Usability
	\item Standardized Surveys for User Experience
	\item user satisfaction questionnaire
	\item public display evaluation
	\item standardized public display evaluation
	\end{itemize}

	% 4) Individual AUTHORS keywoard research
	The last step for collecting relevant papers consisted of profiling publications of two relevant authors in the area of public display research, namely J\"org M\"uller and Marcus Foth. The process started out by first finding a list of their publications. Since the literature review made by Florian Alt (see first step) already covered papers up to 2011, only ones published between 2012 and 2014 were viewed. 
	% procedure
	On each opened papers from this time frame a keyword search was carried out, to see whether it contained an evaluation which might be relevant for us. These keywords were: \textit{questionnaire}, \textit{survey}, \textit{question}, \textit{interview}, \textit{(field) study}, and \textit{evaluation}. If none of these words could be found, the headlines and the abstract was skimmed through. All papers containing a reference to evaluating public displays were saved locally and analyzed in more detail.
	% authors
	For J\"org M\"uller the best list of his publications were found on his personal website\footnote{\url{http://joergmueller.info/publications.html} (accessed on November 17, 2014)}, and for Marcus Foth two websites were evaluated \footnote{\url{http://www.vrolik.de/publications/} (accessed on November 18, 2014) and \url{http://eprints.qut.edu.au/view/person/Foth,_Marcus.html} (accessed on November 18, 2014)}. 

	% 5) Conference Proceedings
		% didn't have time for this step yet, should I just not mention it?





\subsection{Standardized Questionnaires}
\label{sec:questionnaires-categorization}


	% As a result of the literature review process the following overview of questionnaires arose. 
		% % OR % %
	% The findings from literature review were fitted to the categories presented in  research questions found in 

	All questionnaires found during the literature review phase were categorized into a schema, inspired by the research questions introduced by Alt \cite{alt2013thesis} (chapter 2.8.2), serving as a guideline for our classification of standardized questionnaires. Since the categories \textit{audience behavior} and \textit{user performance} from Alt can not be evaluated through questionnaires, the research questions are not represented in the following.
	We extended the prior categorization with findings from the literature review phase, described in the previous section \ref{sec:questionnaires-methodology}, 
	% new categories: usability, context, demographics, other

	A full overview of all standardized questionnaires found in literature can be found in Table \ref{table:standardized-questionnaires}, grouped by the following categories: user experience, usability, user acceptance, user performance, display effectiveness, privacy, social impact, context, and demographics.

	For a list of papers using the standardized questionnaires for evaluation, refer to Appendix \ref{appendix:papers} or pages 54-55 from Alt \cite{alt2013thesis}.



	\subsubsection{User Experience}

		User experience describes the overall satisfaction and experience the user has with a display. The evaluation can be carried out through questionnaires.
	
	\subsubsection{Usability}

	The category was added 

	\subsubsection{User Acceptance}

		User acceptance analyzes user's motives and incentives for approaching the display. The evaluation can be carried out qualitatively (subjective feedback, focus groups) or quantitatively (questionnaires).

	\subsubsection{Display Effectiveness}
		Display effectiveness evaluates the economic perspective of display efficiency. 

	\subsubsection{Privacy}
		Privacy takes a look at the users privacy concerns.

	\subsubsection{Social Impact}
		Social impact considers everything related to social behavior, the influence on social interaction and communities, as well as social effects.

	\subsubsection{Context}

		One category new category, is the collection of context data, relative to the public display. On most normal studies the context doesn't change during evaluation and thus is not as important. For the evaluation of public displays, especially when multiple displays are deployed in different locations running the same application, it will become if importance to also assess the static and dynamic context of each deployed display. External influences such as the weather, time of day, special events or semester break can have an influence on the number and type of people passing by a display. Additionally static context parameters, such as the display type, display size, position on wall and inside of the room might also influence how the display setup is perceived in public. Once recorded, these static and dynamic parameters can be evaluated with knowledge discovery algorithms for big data, a whole research field for itself. 
		So far no previous works are known on this area so far, evaluating a large public display deployment based on their difference in context.

	\subsubsection{Demographics}

		In most surveys background information about the participants is also of interest. This varies from general questions (gender, age, religion, education), more personal questions (relationship status, family, children, country of origin), skills (personal, professional, technical), personal beliefs, political affiliation or voluntary commitment.

		Three background questionnaires, which we haven't used ourselves yet, but which go more in depth, are the Adult Literacy and Lifeskills Survey (ALL) \footnote{\url{http://nces.ed.gov/surveys/all/} (accessed on April 1, 2015)}, the PIAAC Conceptual Framework of the Background Questionnaire Main Survey \footnote{\url{http://www.oecd.org/site/piaac/PIAAC(2011_11)MS_BQ_ConceptualFramework_1 Dec 2011.pdf} (accessed on April 1, 2015)} and a Police Background Questionnaire \footnote{\url{http://www.slmpd.org/images/hr_forms/commissioned/BackgroundQuestionnaire.pdf} (accessed on April 1, 2015)}.



	\subsubsection{Miscellaneous}

		All questions and questionnaires, which can not be assigned to any of the previous categories, belong to this category. 

		Cheverst et al. \cite{cheverst2005hermes} evaluated whether there were any previous experience with Bluetooth, or recommendations for possible new features.
		% TODO REwRITE BOTH SENTENCES!
		For the evaluation of the Digifieds platform Alt et al. also evaluated: ``We asked them about their mobile phone usage (e.g., how often they used it, if it had a touch screen, if they used it to surf the web, and if they had installed third party apps) and whether they had used the UbiDisplays before'' \cite{alt2011digifieds}.







	% % % % % % % % % % % % % % %
	%%%    ADD TABLE HERE    %%%%
	% % % % % % % % % % % % % % %

	\label{table:standardized-questionnaires}

		% ADD A TABLE WITH ALL OF THE QUESTIONNAIRES, A SHORT DESCRIPTION, THE DATE, THE NUMBER OF QUESTIONS, THE REFERENCE HERE

	\begin{enumerate}
		\item POST OR REFERENCE THE TABLE WITH THE CATEGORIZATION HERE
		\item My Categorization: \url{https://docs.google.com/document/d/1D925jJ7bmRc1EZdCTz32lmW2hniMiq7GzBWxX8rmhpE/edit} (Google Docs)
	\end{enumerate}

	% % % % % % % % % % % % % % %
	%%%    ADD TABLE HERE    %%%%
	% % % % % % % % % % % % % % %





\subsection{Findings}
\label{sec:questionnaires-findings}


	% NOT SURE ABOUT THIS ONE HERE, MAYBE COMBINE "FINDINGS" WITH 

	Findings: 
	\begin{enumerate}
	\item use both quantitative and qualitative methods for data collection (explain why this is important, teaser this as a requirement for the platform, how it could be implemented)
	\item support mutliple sections, all displayed at once or (optionally) spread across multiple users
	\item support various question types (e.g. 5-point and 7-point Likert scale, multiple choice, numeric responses, comments)
	\end{enumerate}



%%% Transfer to the next chapter

	These findings bring us to the next chapter, the research platform to develop, capable of conducting all of these questionnaires.










% ALTERNATIVES FOR FIRST SENTENCE

	% Through the literature review, it was a side effect to get a better overview of the questions asked to evaluate public displays and of their applications running on them.

	% As a side effect of the literature review, a side effect was getting an overview of the questions asked to evaluate public displays and of the applications running on them.

	% While performing the literature review, not only getting a better understanding of how public displays are evaluated was a result, but also getting a better overview of the questions asked to evaluate public displays and of their applications running on them
