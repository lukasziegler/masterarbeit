\section{Implementation}
\label{chapter:implementation}
	% Chapter concerning the Technical Realization

	In this chapter we will deal with the infrastructure and technical realization of the public display survey platform. First, the requirements for the survey platform are discussed (section \ref{chapter:implementation:requirements}). Subsequently the architecture resulting from the design decisions will be the main focus (section \ref{chapter:implementation:design-decisions}). To facilitate the training period for successors we will also take a brief look at the software model (section \ref{chapter:implementation:modeling}). For more specific information and for information regarding maintenance of the project, please refer to the documentation found on the CD enclosed (see Appendix \ref{appendix:cd-contents}) or on the GitHub repository\footnote{\url{https://github.com/lukasziegler/masterarbeit/tree/master/docs} (last accessed on April 15, 2015)}.

	In figure \ref{fig:4-pdsurvey-platform} a brief overview of the PDSurvey platform and its components is given. The platform consists of three major parts: a backend for display providers (PDAdmin), a RESTful server (PDServer) and the user interface itself, being embedded on the end user devices (public displays, tablets, smartphones or other devices). 





\subsection{Requirements}
\label{chapter:implementation:requirements}

	Initial requirements were set by the problem statement of the thesis\footnote{\url{http://www.medien.ifi.lmu.de/lehre/arbeiten/detail.xhtml-php?pub=alt_pdsurvey} (last accessed on March 24, 2015)}. These requirements were also a trigger for further literature review and talks with people from the industry. The full listing of the initial problem statement is as follows.

	% Official Problem statement
	\begin{enumerate}[itemsep=0pt] 
	\item \textit{development of a survey tool} that allows interactive public display installations to be comprehensively assessed 
	\item implementation of a web-based survey platform that can easily be used to evaluate and compare public displays through \textit{different channels} 
	\item \textit{different channels} to support: 1) evaluation directly at
	the display or 2) through a (mobile) website that allows participation via smartphone or tablet.
	\item \textit{configuration options} for public display owners
	\end{enumerate}

	Additional requirements, that emerged during research and in discussions, are listed below:

	% Derived requirements
	\begin{itemize}[itemsep=0pt] 
	\item easy \textit{embedding of questionnaires} on websites of public display owners (provide API / embed code)
	\item support of \textit{various devices}: public displays of all sizes, tablets, phablets, smartphones, desktop devices (responsive web design)
	\item easy \textit{scalability} of platform; host on a cloud platform
	\item use a \textit{modular} approach for development, allowing successors to extend and further refine the platform
	\item support \textit{non web-based platforms}, which are not capable of embedding a website or making REST calls
	\item focus on \textit{public display evaluation}, take the context into account for evaluation
	\end{itemize}


	These requirements combined with knowledge from literature review (see section \ref{section:questionnaires:findings}), are what makes this platform unique. The long term goal is to create a research platform, optimized for public display evaluation, delivering new insights into how users react to public display setups. Additionally, the requirements mentioned by Huang et al. \cite{huang2008overcoming} and Jacucci et al. \cite{jacucci2010worldsofinformation} also influenced the concept and development of the survey platform. All of the mentioned requirements had an impact on the chosen architecture, which will be discussed in the next section.



\subsection{Design Decisions}
\label{chapter:implementation:design-decisions}

	Having assessed all requirements for the platform (see section \ref{chapter:implementation:requirements}), the next step was making design decisions for the programming language and frameworks to use, before starting with the practical implementation of the platform. All options were checked, on the one hand to get informed about what is currently trending, on the other hand because every decision made has a substantial impact on the architecture.


	\paragraph{Programming language}

		Due to the requirements and objective to support a large number of devices, operating systems, and form factors, a device-independent programming language was preferred. 
		The choice was made of Javascript, not just due to the growing popularity\footnote{\url{http://www.sitepoint.com/javascript-internet-things/} (last accessed on November 27, 2014)}, but also because it can be used on the largest number of platforms and devices. Another huge benefit is the ability to use JavaScript for all tiers of development, from client to server to persistence layer. Using the same language on all tiers allows us to share some parts of code between server and client. This approach has become very popular in recent years, now often being encapsulated in a technology stack referred to as the MEAN stack, consisting of MongoDB, Express.js, Angular.js, and Node.js. Some fundamental differences to the LAMP stack (Linux, Apache, MySQL, PHP) are its shift form server-side to client-side single-page applications (SPA), faster prototyping, shift from synchronous to asynchronous, fast page loading times, less time spent writing SQL (schemaless), and the shift to using RESTful services for the backend. \cite{Scott2014MEANStack}

		At this point, first thoughts of using the MEAN stack\footnote{\url{http://mean.io/} (last accessed on March 26, 2015)} for the entire development arose. Nonetheless, each part of the architecture was compared and evaluated separately, in order to find the optimal solution for this project. Alternative languages considered were: PHP, Python, Ruby, Java and ASP.NET. The biggest drawback was the additional workload on having to maintain the object model on multiple platforms. Javascript reduces the number of models needing maintenance to one. This way consistency across all platforms (backend, frontend, server) can be achieved easily.
		Based on our requirements of the platform, the feedback received from discussions with industry experts, and the desire to be able to embed questionnaires on 3rd party website, the choice to use JavaScript for the whole development process already became evident. 


	\paragraph{Frontend}

		In recent years single page applications (SPA) have become more popular for creating complex websites \cite{Medium2013SPA, Tutsplus2013SPA}. As of 2014, the JavaScript model-view frameworks most frequently used for creating SPA, are Angular.js, Ember.js and Backbone.js. When looking at the numbers and the trend from recent years, Angular.js is the clear favorite \cite{AirPair2014MEAN}. It has by far the largest user base on GitHub, Stackoverflow, and Youtube. When comparing the number of third-party modules, Angular.js also takes the lead with 800 ngmodules vs. 236 Backbone.js backplugs vs. 21 emberaddons. All these factors together indicate a short training time and give hope for beginners making fast progress. One of the biggest benefits of using a framework like Angular.js, is the ability to use two-way data-binding. Changes made to the model are automatically represented in the UI, and vice versa. Furthermore, the possibility to use the templating functionality, combined with the custom directives in Angular.js, was a big plus for this choice. This functionality was used for creating custom HTML tags for the question types in our surveys. These were, amongst others, the reasons why we chose Angular.js for this project, hoping that it will also simplify the ramp-up time for other students.

		To speed up frontend development we chose Bootstrap\footnote{\url{http://getbootstrap.com/} (last accessed on December 1, 2014)} as our CSS framework of choice. Reasons for choosing Bootstrap were the large community, extensive documentation with helpful examples, large number of free tutorials and templates, its excellent integration with Angular.js (AngulatStrap\footnote{\url{http://mgcrea.github.io/angular-strap/}} and AngularUI), the short training time, and its broad acceptance.
		Alternatives considered were Foundation Framework by Zurb. However, at the time of writing there was no prefabricated integration for Foundation and Angular.js.
		Additional frameworks were also taken into consideration, evaluated using the following overview\footnote{\url{http://www.sitepoint.com/5-most-popular-frontend-frameworks-compared/} (last accessed on December 2, 2014)} and comparison\footnote{\url{http://www.sitepoint.com/grid-system-comparison-bootstrap-vs-foundation/} (last accessed on March 24, 2015)} of currently popular frontend frameworks.
	

	\paragraph{Backend}

		For the backend it was of importance to have a solid performance and scalable solution. Because our system has a multiplicity of clients submitting and querying questionnaires to the survey platform, scalability is of importance in order to be future proof. Additionally, it was of importance to offer an interface for administrators and to be able to easily be able to exchange data with a large number of clients. For this reason a backend built solely on the principles of a RESTful API was preferred. This allows us to query data no matter from which client.
		% get curve to MEAN, say why we chose it now
		Based on the decision to use JavaScript for all tiers, it was also clear to use Node.js as the underlying platform for building web applications. Reasons speaking for Node.js are its event-based and modular approach, only requiring the parts needed for your project. Another benefit is the easy implementation of authentication and internationalization, due to the concept of middlewares \cite{Heise2014RESTConnect} and the native serialization of JSON. Furthermore it is ideal for reusing code, due to its modular and lightweight architecture and the npm package manager\footnote{\url{http://stackoverflow.com/questions/5062614/how-to-decide-when-to-use-node-js} (last accessed on April 9, 2015)} \cite{Heise2014NodeProCon}. To simplify and speed up development with Node.js, Express.js\footnote{\url{http://expressjs.com/} (last accessed on April 10, 2015)} was chosen as the web application framework. Alternatives considered were Connect (simpler, less functionality, predecessor of Express), Koa\footnote{\url{http://koajs.com/} (last accessed on April 10, 2015)} (generator concept) and Resitfy\footnote{\url{http://mcavage.me/node-restify/} (last accessed on April 10, 2015)} (Express reduced for pure REST services). 

		% Communication: RESTful interaction
		Due to the decision of building a single-page application, it became vital to separate the data from presentation layer. Using a RESTful service is the current de facto standard. An alternative would be to use SOAP for message exchange. This would not only lead to an increase of data overhead, but also to a higher complexity on the server-side, and to the loss of statelessness in the requests. In the case that a client does not support HTML or JavaScript execution, the required surveys can still be requested directly through HTTP function calls from the REST API. Such an exception was Quest3D\footnote{\url{http://documentation.quest3d.com/index.php?title=FAQ\#What_is_Quest3D.3F} (last accessed on April 10, 2015)}, a software package used by Jiamin Shi for the development of the Balloon Shooter game. When in a situation where HTTP calls are not supported natively, then one can still use logging combined with a scheduled task or create a proxy on the operating system layer and tunnel all data to \textit{PDServer}.





	\paragraph{Database}

		Another fundamental aspect presented the question of where to store the data permanently. Criteria for choosing the right database management system (DBMS) for this project was made according to criteria like the size of community, suitability for prototyping, and ease of integration with Node.js/Angular.js. The first question presented was whether to choose a SQL or a NoSQL DBMS. We chose NoSQL for this project, because of better scalability, a schemaless data representation, faster response time and a decreased development time\cite{vaish2013getting}. Otherwise, NoSQL is better suited for rapid prototyping, because multiple schemata can be mixed inside of one collection and easier evolve more easily over time. 
		% These are all arguments speaking for using a NoSQL DBMS for our scenario. 

		Out of the NoSQL databases MondoDB\footnote{\url{http://www.mongodb.org/} (last accessed on March 26, 2015)} represents the most popular DBMS, especially since it integrates seamlessly into the MEAN stack. Benefits of MongoDB are that it is non-relational (and schemaless), along with its ability to directly store JavaScript objects inside the database. Other characteristics of MongoDB are the non-blocking write operations, which is ideal for logging data. MongoDB provides a good compromise between scalability/performance and the depth of functionality. One disadvantage is that MongoDB does not support joins or transactions. For our use case, however, this is no major drawback. The benefits outweigh the disadvantages. Alternatives that we looked at were CouchDB and Redis. Redis is useful for fast changing data, which is not required on our platform. CouchDB would be an alternative worth looking at, as it has a better replication and conflict resolution. However, this additional security is not needed. The speed benefits of MongoDB are preferred.\footnote{\url{http://kkovacs.eu/cassandra-vs-mongodb-vs-couchdb-vs-redis} (last accessed on March 26, 2015)}
		
		To facilitate the object modeling process in Node.js, Mongoose\footnote{\url{http://mongoosejs.com/} (last accessed on November 14, 2014)} was chosen, providing object relational mapping. Mongoose is an object modeling package for Node.js, allowing application data to be modeled based on schemata. Mongoose takes care of performing CRUD applications and simplifies the process of keeping the object model synchronized across all layers.


	\paragraph{Hosting}

		For the hosting of the platform a free and easy scalable solution was of importance. Services offering Platform as a Service (PaaS) were preferred over ones offering Infrastructure as a Service (IaaS), because our focus is on developing and evaluating the platform. We considered the following platforms: Heroku (PaaS), IBM BlueMix (PaaS), Google App Engine (PaaS), Amazon AWS (IaaS), or hosting the entire platform on a local machine.

		Our first choice was Heroku\footnote{\url{https://www.heroku.com/} (last accessed on March 26, 2015)}, due to its simple setup, its native support of Node.js, and seamless integration with Mongolab\footnote{\url{https://mongolab.com/} (last accessed on March 26, 2015)}, a platform for hosting MongoDB collections.
		IBM BlueMix was considered as an alternative, which was recently overhauled and now offers full out-of-the-box Node.js support. However, only the first 30 days are free and the pricing model wasn't as attractive. Google App Engine still has no native support for Node.js (as of December 2014) and custom runtimes had to be used to get Node.js support up and running. Amazon Web Services, offering Infrastructure as a Service (IaaS), would have required too much administration of the server. This would have slowed down the main objective of the project, the development of the survey platform\footnote{\url{http://smashingboxes.com/ideas/heroku-vs-amazon-web-services} (last accessed on April 10, 2015)}. The same goes for the last option, hosting a MEAN-stack environment on our own servers at LMU Munich. All of the above are well-known solutions in the industry. However, due to simplicity and ease of use we chose Heroku. For our requirements during the prototype phase Heroku was sufficient, offering one free Heroku \textit{dyno} \cite{Heroku2014Dyno}.






\clearpage

\subsection{Modeling}
\label{chapter:implementation:modeling}

	The development process of the \textit{PDSurvey} platform was inspired and influenced by the concept of extreme programing\footnote{\url{http://www.extremeprogramming.org/rules.html} (last accessed on April 10, 2015)}, making iterative improvements, and working agile and user-centered. First user stories were written and assessed in a small group\footnote{\url{http://www.tigertech.de/wie-schreibe-ich-eine-gute-user-story-und-was-ist-das-uberhaupt/} (last accessed April 10, 2015)}. The next step was to transfer these stories to user models, describing in detail which functionality the stakeholders of \textit{PDSurvey} are supposed to have. Later a first software architecture and software model was built. Dependencies between models were defined and the model was continuously refined and improved throughout the development phase. The last phase included screen designs, getting a clear view of what the interface should later look like.

	% REST API
	The development of the REST API was influenced by current best practices \cite{Sahni2015RESTAPI, TutsPlus2015RESTAPI, hughes2012einfuhrung}. The API is separated into logical resources, while each resource gets manipulated through an HTTP request. For public access GET and POST methods are defined, for authenticated users also PUT and DELETE methods. For a more information about PDSurvey's REST API refer to the documentation (see Appendix \ref{appendix:cd-contents}).
	% Mongoose + REST API
	The model for the \textit{PDSurvey} platform is maintained with Mongoose. Angular.js builds its model from the REST API, and maps all changes via dynamic two-way-binding to it's scope. The REST API is provided by the Node.js server, which maps all incoming requests through an Express router to the corresponding Mongoose models. Thus all changes to the model originate from Mongoose.
	% Our Software Model
	The software model is modeled in Mongoose and stored as MongoDB collections. There are the following collections: Question, QuestionType, Response, Category, Surveys, DisplayModel, Display, Campaign, Context, and User. 
	Of special interest are the following four collections: Surveys, Display, Campaign and Responses (see figure \ref{fig:4-dependency-campaign}).


	% USER ROLES
	% Currently three user roles are implemented for the platform: an \textit{admin} role (for administrators), an \textit{expert} mode (with a mapping of n surveys to m displays), and a \textit{novice} mode (with a simplified interface).


\begin{figure}[bph]
    \begin{center}
        \includegraphics[width=.8\columnwidth]{img/4_implementation/4-dependency-campaign}
    \end{center}
 % \begin{center}\LARGE [BILD]\end{center}
 \caption{Campaign model dependencies}
 \label{fig:4-dependency-campaign}
\end{figure}


	\paragraph{Surveys:} Surveys are the foundation of PDSurvey. In the current version of \textit{PDSurvey} questionnaires are implemented as one possible method for assessing the users' opinion. The `Survey' model consists of multiple sections, which in turn are made up of multiple questions. Each question is of a corresponding question type and every questionnaire belongs to a category. This allows questionnaires to be filtered based on certain research questions. Additionally we added the ability to set surveys \textit{private} (by default), \textit{shared} (for sharing with other users), \textit{standardized} (scientifically recognized), or \textit{pending} (waiting for review, to be shared). Every survey is assigned to an individual user of the platform, with the aim of reuse and standardization of questionnaires.

	\paragraph{Display:} In the display collection all displays connected to the PDSurvey platform are contained. To allow evaluation across multiple display models and based on the context of the displays, the display model and a static and/or dynamic context is assigned to it.

	\paragraph{Campaign:} Campaigns resemble the most integral part of the platform. Each campaign consists of multiple displays and multiple surveys, resulting in a mapping of  surveys to public display networks. Additionally, to each of those mappings an individual context can be assigned, enabling a comparison of results of public displays later on.

	\paragraph{Response:} All responses made to each survey are logged in the Response collection. The queries are logged individually per user, per display and per campaign. This model will be the base for further extensions, such as the automatic evaluation of the survey responses and the comparison of different displays inside one display network. This enables the administrator to find out which properties of a display might cause certain effects.

	\paragraph{Context:} One of the benefits of creating this survey platform is the ability to collect and evaluate large amounts of data, without increasing the workload on the human component for conducting and evaluating the responses. The idea is to collect a large number of responses from a variety of displays in various settings, and assign a specific context to every display connected to PDSurvey. Once enough data is collected, the results can be evaluated and compared between the displays. Interesting questions for analysis would be, what role the context plays on how the users respond to the display, when running identical software settings on the displays, but only varying the context (position, size of display, surrounding environment of the display, positioning it outdoors or indoors, influence of the weather, type of building it is positioned in).



