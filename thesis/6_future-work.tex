\section{Future Work}
\label{chapter:future-work}

	% get inspired by: http://publications.lib.chalmers.se/records/fulltext/131908.pdf
	

\paragraph{Research Questions}

	Research questions which came up during the six month editing period of the thesis

	\begin{itemize}
	\item In which situations is the user most willing to answer surveys on public displays? What influence does the context and surrounding environment have on the survey responses?
	\item How many questions are acceptable and tolerated? Does this variable differ between the feedback channels, location of the display setup, and its surrounding environment? Which other factors play a role here?
	\item What is the ideal placement for surveys to pop up on a public display? Where should an overlay be positioned, when embedding it into a foreign application? How large/small, how obtrusive should it be?
	% \item According to Joerg Mueller: the best position on large public displays is directly in the center (not at the bottom, not at the top, close to the center). The larger the screen is, the more relevant a centric positioning will get.
	\item Getting a better understanding of the influence of the environment, e.g. how personal questions can get in public, and how much privacy the display should offer (the smaller the display, the more private the context seems).
	\item How can we best break down a standardized survey with 10+ questions across multiple users, each getting their own subset of questions?
	\item When is the best timing for interrupting a user from his primary task? What are the chances that he will take the time to answer questionnaires in public? How can we best integrate questionnaires on and after the application itself.
	\end{itemize}



\paragraph{Survey Platform}

	\begin{enumerate}
	\item Logging, adding more data sources (for tracking of ``User performance'', see chapter \ref{sec:questionnaires})
	\item Support the logging of video feeds. One possible approach would be to save the raw data in a dropbox account, to submit the file names via REST calls, and to access the files from PDSurvey via the Dropbox API
	\item Dynamically evaluating \textit{reliability} and \textit{validity} in the platform, ideally on-the-fly.
	\item also for pervasive displays?
	\end{enumerate}


\paragraph{Evaluation}

	\begin{enumerate}
	\item Number of questions tollerated on each evaluation channel (public display, tablet, smartphone, laptop/desktop)
	\item to also impose variables: context, content, location / setting and to vary those in experimental studies
	\item splitting 
	\item finding the similarities between different standardized questionnaires. As Jacucci et al. \cite{jacucci2010worldsofinformation} mentioned, there are often significant similarities between standardized questionnaires. It might be possible to break down each questionnaire to its principal parts, to bundle all conformities, in order to reduce the total amount of questions and to be able to split all questions across multiple users on the same display.
	\end{enumerate}


\paragraph{Other}
	\begin{enumerate}
	\item How should a survey be constructed to take best advantage of the PDSurvye platform? How many quantitative and how many qualitative questions?
	\end{enumerate}


